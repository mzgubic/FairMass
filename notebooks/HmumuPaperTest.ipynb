{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare low level, high level, and both features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../fairml')\n",
    "import plotting\n",
    "import generate as G\n",
    "import models\n",
    "import actions\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "var_sets = ['low', 'high', 'both']\n",
    "\n",
    "# get the scalers, and the convenince function\n",
    "x_scaler, z_scaler, generate = {}, {}, {}\n",
    "\n",
    "for v in var_sets:\n",
    "    x_scaler[v], z_scaler[v], generate[v] = G.generate_hmumu(features=v)\n",
    "\n",
    "# generate test data (a large, one time only thing)\n",
    "n_test_samples = 100000\n",
    "X, Y, Z, W, Z_plot = {}, {}, {}, {}, {}\n",
    "\n",
    "for v in var_sets:\n",
    "    X[v], Y[v], Z[v], W[v] = generate[v](n_test_samples, balanced=False) # need Global weights for testing\n",
    "    Z_plot[v] = z_scaler[v].inverse_transform(Z[v], copy=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a sklearn benchmark performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_train_samples = 10000\n",
    "\n",
    "# create training samples\n",
    "X_train, Y_train, W_train = {}, {}, {}\n",
    "for v in var_sets:\n",
    "    X_train[v], Y_train[v], _, W_train[v] = generate[v](n_train_samples, balanced=True)\n",
    "\n",
    "# train\n",
    "gbc100, preds100, gbc400, preds400 = {}, {}, {}, {}\n",
    "fpr100, tpr100, fpr400, tpr400 = {}, {}, {}, {}\n",
    "\n",
    "for v in var_sets:\n",
    "\n",
    "    # train 100 and 400 benchmarks\n",
    "    gbc100[v] = GradientBoostingClassifier(n_estimators=100)\n",
    "    gbc100[v].fit(X_train[v], Y_train[v], sample_weight=W_train[v])\n",
    "    preds100[v] = gbc100[v].predict_proba(X[v])[:, 1]\n",
    "\n",
    "    gbc400[v] = GradientBoostingClassifier(n_estimators=400)\n",
    "    gbc400[v].fit(X_train[v], Y_train[v], sample_weight=W_train[v])\n",
    "    preds400[v] = gbc400[v].predict_proba(X[v])[:, 1]\n",
    "\n",
    "    # roc curve\n",
    "    fpr100[v], tpr100[v], _ = roc_curve(Y[v], preds100[v], sample_weight=W[v])\n",
    "    fpr400[v], tpr400[v], _ = roc_curve(Y[v], preds400[v], sample_weight=W[v])\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "cols = {'low':utils.light_blue, 'high':utils.blue, 'both':utils.oxford_blue}\n",
    "for v in var_sets:\n",
    "    ax.plot(1-fpr100[v], tpr100[v], color=cols[v], linestyle=':', label='GBC 100 ({})'.format(v))\n",
    "    ax.plot(1-fpr400[v], tpr400[v], color=cols[v], linestyle='-', label='GBC 400 ({})'.format(v))\n",
    "ax.legend(loc='best')\n",
    "ax.set_xlabel('Background rejection')\n",
    "ax.set_ylabel('Signal efficiency')\n",
    "plt.show()\n",
    "\n",
    "# save the benchmarks for the performance comparison\n",
    "fprs = {v:fpr400[v] for v in var_sets}\n",
    "tprs = {v:tpr400[v] for v in var_sets}\n",
    "labels = {v:'GBC400 ({})'.format(v) for v in var_sets}\n",
    "benchmarks = fprs, tprs, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train neural nets on low, high level features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "ctr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "n_epochs = 10\n",
    "learning_rate = 0.005\n",
    "deep = True\n",
    "ctr+=1\n",
    "name = 'name'+str(ctr)\n",
    "\n",
    "# input placeholders\n",
    "x_in, y_in, z_in, w_in, inputs = {}, {}, {}, {}, {}\n",
    "for v in var_sets:\n",
    "    x_in[v] = tf.placeholder(tf.float32, shape=(None, X[v].shape[1]), name='X'+v)\n",
    "    y_in[v] = tf.placeholder(tf.float32, shape=(None, ), name='Y'+v)\n",
    "    z_in[v] = tf.placeholder(tf.float32, shape=(None, ), name='Z'+v)\n",
    "    w_in[v] = tf.placeholder(tf.float32, shape=(None, ), name='W'+v)\n",
    "    inputs[v] = [x_in[v], y_in[v], z_in[v], w_in[v]]\n",
    "\n",
    "\n",
    "# create the classifier graph, loss, and optimisation\n",
    "clf_output, vars_D, loss_D, opt_D = {}, {}, {}, {}\n",
    "for v in var_sets:\n",
    "    clf_output[v], vars_D[v] = models.classifier(x_in[v], name+'_clf'+v, deep=deep)\n",
    "    loss_D[v] = models.classifier_loss(clf_output[v], y_in[v], w_in[v])\n",
    "    opt_D[v] = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_D[v], var_list=vars_D[v])\n",
    "\n",
    "# initialise the variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train the classifiers\n",
    "for e in range(n_epochs):\n",
    "    \n",
    "    # report on progress\n",
    "    if e%10 == 0:\n",
    "        print('{}/{}'.format(e, n_epochs))\n",
    "    \n",
    "    # training step and roc curve compuation\n",
    "    npreds, nfprs, ntprs, nlabels = {}, {}, {}, {}\n",
    "    for v in var_sets:\n",
    "        actions.train(sess, opt_D[v], loss_D[v], inputs[v], generate[v], n_samples, 1, None)\n",
    "        npreds[v] = utils.sigmoid(sess.run(clf_output[v], feed_dict={x_in[v]:X[v]}))\n",
    "        nfprs[v], ntprs[v], _ = roc_curve(Y[v], npreds[v], sample_weight=W[v])\n",
    "        nlabels[v] = 'NN {}'.format(v)\n",
    "    \n",
    "    nets = nfprs, ntprs, nlabels\n",
    "    \n",
    "    # plot\n",
    "    pname = 'VarsComparison'\n",
    "    dirn = 'media/plots/{}'.format(pname)\n",
    "    if not os.path.exists(dirn):\n",
    "        os.makedirs(dirn)\n",
    "    path = '{d}/{n}_{c:03}.png'.format(d=dirn, n=pname, c=e)\n",
    "    \n",
    "    plotting.plot_var_sets(benchmarks, nets, path, batch=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
