{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/zgubic/Projects/FairMass/fairmass')\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_MI(gen_x, gen_y, n_epochs=200, H=20, name='name'):\n",
    "\n",
    "    # prepare the placeholders for inputs\n",
    "    x_in = tf.placeholder(tf.float32, [None, 1], name='x_in')\n",
    "    y_in = tf.placeholder(tf.float32, [None, 1], name='y_in')\n",
    "\n",
    "    # make the loss and optimisation graphs\n",
    "    T_xy, T_x_y, mine_vars = models.MINE(x_in, y_in, name, deep=False)\n",
    "    neg_loss = models.MINE_loss(T_xy, T_x_y)\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=0.01).minimize(neg_loss)\n",
    "    \n",
    "    deep_T_xy, deep_T_x_y, deep_mine_vars = models.MINE(x_in, y_in, 'deep_'+name, deep=True)\n",
    "    deep_neg_loss = models.MINE_loss(deep_T_xy, deep_T_x_y)\n",
    "    deep_opt = tf.train.AdamOptimizer(learning_rate=0.01).minimize(deep_neg_loss)\n",
    "    \n",
    "    # run the session and training\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # train\n",
    "    MIs = []\n",
    "    deep_MIs= []\n",
    "    for epoch in range(n_epochs):\n",
    "        x_sample=gen_x()\n",
    "        y_sample=gen_y(x_sample)\n",
    "    \n",
    "        feed_dict = {x_in:x_sample, y_in:y_sample}\n",
    "        _, _, neg_l, deep_neg_l = sess.run([opt, deep_opt, neg_loss, deep_neg_loss], feed_dict=feed_dict)\n",
    "    \n",
    "        MIs.append(-neg_l)\n",
    "        deep_MIs.append(-deep_neg_l)\n",
    "\n",
    "    # compute true MI\n",
    "    x=gen_x()\n",
    "    y=gen_y(x)\n",
    "    mi = mutual_info_regression(x.reshape(-1, 1), y.ravel())[0]\n",
    "    \n",
    "    # plot\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # data\n",
    "    ax[0].scatter(x, y, marker='x')\n",
    "    ax[0].set_xlabel('x')\n",
    "    ax[0].set_ylabel('y')\n",
    "    \n",
    "    # MINE performance\n",
    "    ax[1].plot(range(len(MIs)), MIs, label='MINE estimate')\n",
    "    ax[1].plot(range(len(deep_MIs)), deep_MIs, label='deep MINE estimate')\n",
    "    ax[1].plot([0, len(MIs)], [mi,mi], label='True MI')\n",
    "    ax[1].set_title('MINE for {}'.format(name))\n",
    "    ax[1].set_xlabel('training steps')\n",
    "    ax[1].set_ylabel('MI (loss)')\n",
    "    ax[1].legend(loc='best')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_size = 2000\n",
    "\n",
    "# vanilla option\n",
    "def gen_x():\n",
    "    vec =  np.sign(np.random.normal(0.,1.,[data_size,1]))\n",
    "    return(vec)\n",
    "def gen_y(x):\n",
    "    vec =  x + np.random.normal(0.,np.sqrt(0.2),[data_size,1])\n",
    "    return vec\n",
    "plot_MI(gen_x, gen_y, 200, 20, 'vanilla200_20')\n",
    "\n",
    "# independent\n",
    "def gen_ind_x():\n",
    "    return np.random.normal(0, 1, data_size).reshape(-1, 1)\n",
    "def gen_ind_y(_):\n",
    "    vec = np.random.normal(1, 1, data_size) + 10 * (0.5 - np.random.binomial(1, 0.5, size=data_size))\n",
    "    return vec.reshape(-1, 1)\n",
    "plot_MI(gen_ind_x, gen_ind_y, 200, 20, 'independent200_20')\n",
    "    \n",
    "# harder (more spread)\n",
    "def gen_dep_x():\n",
    "    return np.random.normal(0, 1, data_size).reshape(-1, 1)\n",
    "def gen_dep_y(x):\n",
    "    N = data_size\n",
    "    vec =  np.random.normal(0, 0.1, N) + 2*(0.5 - np.random.binomial(1, 0.5, size=N)) * np.abs(1-x.ravel()**2)**0.5\n",
    "    return vec.reshape(-1, 1)\n",
    "plot_MI(gen_dep_x, gen_dep_y, 200, 20, 'dependent200_20')\n",
    "plot_MI(gen_dep_x, gen_dep_y, 2000, 20, 'dependent2000_20')\n",
    "plot_MI(gen_dep_x, gen_dep_y, 200, 50, 'dependent200_50')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
