{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINE minimal working example\n",
    "\n",
    "This notebook gives an example of computing the mutual information using Mutual Information Neural Estimator (see 1801.04062) using Tensorflow.\n",
    "\n",
    "It is based on the Torch implementation at: https://github.com/MasanoriYamada/Mine_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import mutual_info_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data of two dependent variables with non zero MI. Compute it analytically and numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "var = 0.2\n",
    "def func(x):\n",
    "    return x\n",
    "\n",
    "def gen_x():\n",
    "    return np.sign(np.random.normal(0.,1.,[data_size,1]))\n",
    "\n",
    "def gen_y(x):\n",
    "    return func(x)+np.random.normal(0.,np.sqrt(var),[data_size,1])\n",
    "\n",
    "data_size = 20000\n",
    "x=gen_x()\n",
    "y=gen_y(x)\n",
    "p_y_x=np.exp(-(y-x)**2/(2*var))\n",
    "p_y_x_minus=np.exp(-(y+1)**2/(2*var))\n",
    "p_y_x_plus=np.exp(-(y-1)**2/(2*var))\n",
    "mi=np.average(np.log(p_y_x/(0.5*p_y_x_minus+0.5*p_y_x_plus)))\n",
    "print(mi)\n",
    "mi_numerical = mutual_info_regression(x.reshape(-1, 1), y.ravel())[0]\n",
    "print(mi_numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the MINE network and train it. Plot convergence of the loss towards true MI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "H=20\n",
    "n_epochs = 200\n",
    "data_size = 20000\n",
    "\n",
    "def MINE(x_in, y_in):\n",
    "    \n",
    "    # shuffle the data and append to the end (so that they are processed by the same net)\n",
    "    y_shuffle = tf.random_shuffle(y_in)\n",
    "    x_conc = tf.concat([x_in, x_in], axis=0)\n",
    "    y_conc = tf.concat([y_in, y_shuffle], axis=0)\n",
    "    \n",
    "    # propagate the forward pass\n",
    "    layerx = layers.linear(x_conc, H)\n",
    "    layery = layers.linear(y_conc, H)\n",
    "    layer2 = tf.nn.relu(layerx + layery)\n",
    "    output = layers.linear(layer2, 1)\n",
    "    \n",
    "    # split in T_xy and T_x_y predictions\n",
    "    N_samples = tf.shape(x_in)[0]\n",
    "    T_xy = output[:N_samples]\n",
    "    T_x_y = output[N_samples:]\n",
    "    \n",
    "    # compute the negative loss (maximise loss == minimise -loss)\n",
    "    neg_loss = -(tf.reduce_mean(T_xy, axis=0) - tf.math.log(tf.reduce_mean(tf.math.exp(T_x_y))))\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=0.01).minimize(neg_loss)\n",
    "\n",
    "    return neg_loss, opt\n",
    "\n",
    "# prepare the placeholders for inputs\n",
    "x_in = tf.placeholder(tf.float32, [None, 1], name='x_in')\n",
    "y_in = tf.placeholder(tf.float32, [None, 1], name='y_in')\n",
    "\n",
    "# make the loss and optimisation graphs\n",
    "neg_loss, opt = MINE(x_in, y_in)\n",
    "\n",
    "# start the session\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train\n",
    "MIs = []\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # generate the data\n",
    "    x_sample=gen_x()\n",
    "    y_sample=gen_y(x_sample)\n",
    "    \n",
    "    # perform the training step\n",
    "    feed_dict = {x_in:x_sample, y_in:y_sample}\n",
    "    _, neg_l = sess.run([opt, neg_loss], feed_dict=feed_dict)\n",
    "    \n",
    "    # save the loss\n",
    "    MIs.append(-neg_l)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(len(MIs)), MIs, label='MINE estimate')\n",
    "ax.plot([0, len(MIs)], [mi,mi], label='True Mutual Information')\n",
    "ax.set_xlabel('training steps')\n",
    "ax.legend(loc='best')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
