{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../fairml')\n",
    "import plotting\n",
    "import generate as G\n",
    "import models\n",
    "import actions\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the scalers, and the convenince function\n",
    "x_scaler, z_scaler, generate = G.generate_hmumu()\n",
    "\n",
    "# generate test data (a large, one time only thing)\n",
    "n_test_samples = 1000000\n",
    "X, Y, Z, W = generate(n_test_samples, balanced=False) # need Global weights for testing\n",
    "Z_plot = z_scaler.inverse_transform(Z, copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a sklearn benchmark performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, _, W_train = generate(10000, balanced=True)\n",
    "\n",
    "# train\n",
    "gbc100 = GradientBoostingClassifier(n_estimators=100)\n",
    "gbc100.fit(X_train, Y_train, sample_weight=W_train)\n",
    "preds100 = gbc100.predict_proba(X)[:, 1]\n",
    "\n",
    "gbc400 = GradientBoostingClassifier(n_estimators=400)\n",
    "gbc400.fit(X_train, Y_train, sample_weight=W_train)\n",
    "preds400 = gbc400.predict_proba(X)[:, 1]\n",
    "\n",
    "# roc curve\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr100, tpr100, _ = roc_curve(Y, preds100, sample_weight=W)\n",
    "fpr400, tpr400, _ = roc_curve(Y, preds400, sample_weight=W)\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.plot(1-fpr100, tpr100, label='GBC 100')\n",
    "ax.plot(1-fpr400, tpr400, label='GBC 400')\n",
    "ax.legend(loc='best')\n",
    "ax.set_xlabel('Background rejection')\n",
    "ax.set_ylabel('Signal efficiency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-adversarial training of a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "ctr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "n_epochs = 10\n",
    "learning_rate = 0.005\n",
    "deep = False\n",
    "ctr+=1\n",
    "name = 'name'+str(ctr)\n",
    "\n",
    "# input placeholders\n",
    "x_in = tf.placeholder(tf.float32, shape=(None, X.shape[1]), name='X1_X2')\n",
    "y_in = tf.placeholder(tf.float32, shape=(None, ), name='Y')\n",
    "z_in = tf.placeholder(tf.float32, shape=(None, ), name='Z')\n",
    "w_in = tf.placeholder(tf.float32, shape=(None, ), name='W')\n",
    "inputs = [x_in, y_in, z_in, w_in]\n",
    "\n",
    "# create the classifier graph, loss, and optimisation\n",
    "clf_output, vars_D = models.classifier(x_in, name+'_clf', deep=deep)\n",
    "loss_D = models.classifier_loss(clf_output, y_in, w_in)\n",
    "opt_D = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_D, var_list=vars_D)\n",
    "\n",
    "# initialise the variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train the classifier\n",
    "pname = 'Hmumu'\n",
    "for e in range(n_epochs):\n",
    "    \n",
    "    # report on progress\n",
    "    if e%10 == 0:\n",
    "        print('{}/{}'.format(e, n_epochs))\n",
    "    \n",
    "    # training step\n",
    "    actions.train(sess, opt_D, loss_D, inputs, generate, n_samples, 1, None)\n",
    "\n",
    "    # make predictions on the test\n",
    "    pred = utils.sigmoid(sess.run(clf_output, feed_dict={x_in:X}))\n",
    "\n",
    "    # name of the plot\n",
    "\n",
    "    dirn = 'media/plots/{}'.format(pname)\n",
    "    if not os.path.exists(dirn):\n",
    "        os.makedirs(dirn)\n",
    "    path = '{d}/{n}_{c:03}.png'.format(d=dirn, n=pname, c=e)\n",
    "    \n",
    "    # plot the performance of the classifier\n",
    "    fprs = [fpr100, fpr400]\n",
    "    tprs = [tpr100, tpr400]\n",
    "    titles = ['GBC100', 'GBC400']\n",
    "    benchmarks = fprs, tprs, titles\n",
    "    plotting.plot_hmumu_performance(X, Y, Z_plot, W, pred.reshape(-1), benchmarks, path, batch=True)\n",
    "\n",
    "if not os.path.exists('media/gifs'):\n",
    "    os.makedirs('media/gifs')\n",
    "dirn = 'media/plots/{}'.format(pname)\n",
    "in_pngs = ' '.join(['{d}/{p}_{c:03}.png'.format(d=dirn, p=pname, c=c) for c in range(n_epochs)])\n",
    "out_gif = 'media/gifs/{p}_{c}.gif'.format(p=pname, c=n_epochs)\n",
    "os.system('convert -colors 32 -loop 0 -delay 10 {i} {o}'.format(i=in_pngs, o=out_gif))\n",
    "print(out_gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
